# Cloud Storage {#cloud}

After sensors start to send data it is necessary that you define a place where that data should be stored. In the context of IoT the Cloud is a place somewhere on the internet where a provider allows recognized sensors to store their raw data in a database. You as the owner has access to that database, are able to program it and know how results could be made visible on dashboards. So it is not necessary anymore to maintain your own private servers in your own data centers, but cloud platform companies are now taking over that role.

Raw data is in fact meaningless. You will have to analyze it, reshuffle, run statistics on it, correlate it with other data, watch for exceptional values and so on to make raw sensor data valuable for your business goals. We will touch on data analytics, machine learning and data science in [section 13](#analytics).

In this chapter we will look into data, its place in the IoT infrastructure and explore one of the many cloud solutions.

## Database Systems
As most IoT devices have very limited memory resources, the data they produce has to be stored elsewhere. We discussed the data communication possibilities in [section 8](#communication). In theory the data could be gathered into a simple text file and applications could read from this source.

However we soon would encounter some annoying practical problems. For instance while data is written to a text file it is blocked. This would mean other devices can not add their data resulting in data loss. Also a text file is not the most efficient user of memory and its size would grow exponentially when used in a professional application with large numbers of devices and users. Other issues include lack of search and filtering facilities and connecting to other data tables.

The above mentioned problems are not uniquely related to the IoT system. It translates to any client server environment. Database systems have been developed to cope with the challenges of efficiently creating large quantities of data, read records, and update and delete them. These basic database functionalities have been summarized in the CRUD acronym.

The most common language for doing CRUD operations on a database is SQL (Structured Query Language). It has a rather human friendly syntax. For example this is the instruction for retrieving a selection of data from a data table (what do you think it will return?):
<br>
```
SELECT * FROM SensorData WHERE Weekday = 'Monday'
```

```{r dbtable, echo=FALSE, message=FALSE, warning=FALSE}

# Build a vector with the days of the week
days <- weekdays(x=as.Date(seq(7), origin="1950-01-01"))

# Build a vecotr with device IDs
dev <- as.vector(outer(c("A", "B"), 1:4, paste0))

# Build a vector of sampled weekdays with replacement
randomvec <- as.vector(sample(5:8, 7, replace=TRUE))
Weekday <- rep(days, randomvec)

# Build a vector of sampled devices with replacement and same length as Weekday
l <- length(Weekday)
DeviceID <- sample(dev, l, replace = TRUE)

# Build a vector of random numbers with same length as previous vectors
Temperature <- round(runif(l, min = -9.2, max = -8), 1)

# Combine all vectors in a dataframe
SensorData <- data.frame(DeviceID, Weekday, Temperature)

# Build a table
knitr::kable(head(SensorData, 11), booktabs = TRUE,
  caption = 'An example database table: SensorData'
)
```

<br>
A database consists of many tables. These tables can be related through key variables. For instance one table can contain sensor data while another table contains the meta data per device. These tables can be combined via a shared variable (*field*) containing the device IDs. When the meta data includes location data (e.g. longitude/latitude) you could draw maps with the temperature measurements (click on the markers in the map).
<br>


```{r geocodes, echo=FALSE, message=FALSE, warning=FALSE}
library(leaflet)
library(ggmap)

# Build dataframe with geocodes
cities <- c("MAASSLUIS","ARNHEM","NIJMEGEN","OSS", "ZWOLLE", "DEN HELDER", "GOES", "WAALWIJK")
geoDF <- cbind(DeviceID = dev, cities, geocode(cities))

# Add geocodes to sensor data
sensorDF <- merge(SensorData, geoDF, by="DeviceID") %>% filter(Weekday == 'Monday')

# Create map
leaflet(data = sensorDF) %>% addTiles() %>%
  addMarkers(~lon, ~lat, popup = ~as.character(paste('Temp: ',Temperature)))
```

<br>
Databases that follow the above described structure belong to the category of Relational Database Systems (RDBS). Popular (open source) instances are [PostgreSQL](https://www.postgresql.org/) and [MySQL](https://www.mysql.com/). Another category of database systems that is gaining attention are the NoSQL systems. An example is [MongoDB](https://www.mongodb.com/) (also open source). An important difference between the two categories is that an RDBS can only hold one value per cell in a table (like a spreadsheet), whereas a NoSQL database can hold nested vectors of values in one cell (like [JSON](http://www.json.org/)).
<br>

```{r nosql, echo=FALSE, message=FALSE, warning=FALSE}
library(jsonlite)
library(dplyr)

newDF <- aggregate(Temperature ~ DeviceID + Weekday, SensorData, list) %>% filter(Weekday == 'Monday')
toJSON(newDF, pretty=TRUE)
```
<br>

[Youtube: @google_developers_google_nodate]

<iframe width="560" height="315" src="https://www.youtube.com/embed/rRoy6I4gKWU" frameborder="0" allowfullscreen></iframe>
<br>

Another interesting alternative database architecture is the graph database. In a graph database data is represented as a network where the records are stored in nodes and the relationships in the edges. This is a very convenient solution when you are more interested in the relationships between objects rather than doing aggregations on them (sums, averages, etc).
<br>

[Youtube: @neo4j_-_the_worlds_leading_graph_database_intro_nodate]

<iframe width="560" height="315" src="https://www.youtube.com/embed/83P81ebgCxA" frameborder="0" allowfullscreen></iframe>
<br>


## Things in a network

## Amazon Web Services


